from .weather_service import get_weather_data
from .soil_service import get_soil_data
import json
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

def analyze_and_recommend(lat: float, lon: float):
    """
    Orchestrates data fetching and generates crop recommendations using OpenAI.
    """
    weather = get_weather_data(lat, lon)
    soil = get_soil_data(lat, lon)
    
    if not weather or not soil:
        return {"error": "Failed to fetch necessary environmental data."}

    # Generate Prompt for LLM
    prompt = _generate_agronomy_prompt(
        location={"lat": lat, "lon": lon},
        weather=weather,
        soil=soil
    )
    
    # Call OpenAI
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return {"error": "OPENAI_API_KEY not found in environment."}
        
    client = OpenAI(api_key=api_key)
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o", # Using a capable model
            messages=[
                {"role": "system", "content": "You are a helpful agricultural expert. Output valid JSON only."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )
        
        content = response.choices[0].message.content
        llm_result = json.loads(content)
        recommendations = llm_result.get("recommendations", [])
        
    except Exception as e:
        print(f"OpenAI Error: {e}")
        recommendations = ["Error generating recommendations from AI."]

    return {
        "location": {"lat": lat, "lon": lon},
        "environmental_summary": {
            "temperature": weather.get("current_weather", {}).get("temperature"),
            "soil_type": soil.get("data", [{}])[0].get("soil_type"),
            "soil_texture": soil.get("data", [{}])[0].get("soil_texture", {})
        },
        "recommendations": recommendations,
        "note": "Recommendations generated by AI based on real-time data."
    }

def _generate_agronomy_prompt(location, weather, soil):
    """
    Constructs a detailed prompt for the LLM acting as an expert agronomist.
    """
    soil_data = soil.get("data", [{}])[0]
    
    return f"""
    You are an expert Agronomist.
    
    **Location**: {location['lat']}, {location['lon']}
    **Conditions**:
    - Weather: {weather.get('current_weather', {})}
    - Soil: {soil_data.get('soil_type', 'Unknown')} ({soil_data.get('soil_texture', 'Unknown')})
    - Moisture: {soil_data.get('soil_moisture', 'Unknown')}% | Temp: {soil_data.get('soil_temperature', 'Unknown')}Â°C
    
    **Task**:
    Recommend 3 optimal crops to plant *now*.
    
    **Output Style**:
    - Be extremely concise and direct.
    - No fluff.
    - Focus on *why* it works with the specific soil/weather data provided.
    
    **Format**: JSON.
    {{
        "recommendations": [
            {{
                "crop": "Name",
                "reason": "One short sentence explaining fit.",
                "risk": "One short sentence on main risk."
            }}
        ]
    }}
    """
